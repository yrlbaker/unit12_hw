{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Unit 12 NLP Assigment\r\n",
    "# Section One: \r\n",
    "## Using the newsapi for BTC and ETH to create Sentiment Analysis (SA) for each coin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "from dotenv import load_dotenv\r\n",
    "import nltk as nltk\r\n",
    "nltk.download('vader_lexicon')\r\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
    "analyzer = SentimentIntensityAnalyzer()\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Read your api key environment variable\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Create a newsapi client\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Fetch the Bitcoin news articles\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Fetch the Ethereum news articles\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create the Bitcoin sentiment scores DataFrame\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create the Ethereum sentiment scores DataFrame\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Describe the Bitcoin Sentiment\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Describe the Ethereum Sentiment\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Section Two: Natural Language Processing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize the text for BTC and ETH using NLTK and Python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\r\n",
    "from string import punctuation\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Instantiate the lemmatizer\r\n",
    "\r\n",
    "\r\n",
    "# Create a list of stopwords\r\n",
    "\r\n",
    "\r\n",
    "# Expand the default stopwords list if necessary\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Complete the tokenizer function\r\n",
    "def tokenizer(text):\r\n",
    "    \"\"\"Tokenizes text.\"\"\"\r\n",
    "    \r\n",
    "    # Remove the punctuation from text\r\n",
    "\r\n",
    "   \r\n",
    "    # Create a tokenized list of the words\r\n",
    "    \r\n",
    "    \r\n",
    "    # Lemmatize words into root words\r\n",
    "\r\n",
    "   \r\n",
    "    # Convert the words to lowercase\r\n",
    "    \r\n",
    "    \r\n",
    "    # Remove the stop words\r\n",
    "    \r\n",
    "    \r\n",
    "    return tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new tokens column for Bitcoin\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new tokens column for Ethereum\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using ngrams and word frequency for each coin. \r\n",
    "Use NLTK to produce the n-grams for N = 2. \r\n",
    "List the top 10 words for each coin."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " from collections import Counter\r\n",
    "from nltk import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Bitcoin N-grams where N=2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Ethereum N-grams where N=2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function token_count generates the top 10 words for a given coin\r\n",
    "def token_count(tokens, N=3):\r\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\r\n",
    "    return Counter(tokens).most_common(N)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use token_count to get the top 10 words for Bitcoin\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use token_count to get the top 10 words for Ethereum\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Word Clouds to summarize the news for each coin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from wordcloud import WordCloud\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "plt.style.use('seaborn-whitegrid')\r\n",
    "import matplotlib as mpl\r\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Bitcoin word cloud\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Ethereum word cloud\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section Three: Named Entity Recognition\r\n",
    "## building a named entity recognition model for BTC & ETH\r\n",
    "## visualizing the tags using SpaCy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import spacy\r\n",
    "from spacy import displacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download the language model for SpaCy\r\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the spaCy model\r\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BTC NER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatenate all of the Bitcoin text together\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the NER processor on all of the text\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add a title to the document\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Render the visualization\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List all Entities\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ETH NER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatenate all of the Ethereum text together\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the NER processor on all of the text\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Render the visualization\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List all Entities\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
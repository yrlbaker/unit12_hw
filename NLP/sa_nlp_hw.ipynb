{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Unit 12 NLP Assigment\r\n",
    "# Section One: \r\n",
    "## Using the newsapi for BTC and ETH to create Sentiment Analysis (SA) for each coin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "from dotenv import load_dotenv\r\n",
    "import nltk as nltk\r\n",
    "from newsapi import NewsApiClient\r\n",
    "nltk.download('vader_lexicon')\r\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
    "analyzer = SentimentIntensityAnalyzer()\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read your api key environment variable\r\n",
    "api_key = os.getenv(\"news_api\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Create a newsapi client\r\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Fetch the Bitcoin news articles\r\n",
    "bitcoin_articles = newsapi.get_everything(\r\n",
    "    q = \"bitcoin\"\r\n",
    "    language = \"en\")\r\n",
    "\r\n",
    "#Total bitcoin article results\r\n",
    "print(f\"Bitcoin article total: {bitcoin_articles[\"TotalResults\"]}\")\r\n",
    "\r\n",
    "#Print second bitcoin article result\r\n",
    "bitcoin_articles[\"articles\"][1]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-87bbe8d19dff>, line 4)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-87bbe8d19dff>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    language = \"en\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Fetch the Ethereum news articles\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create the Bitcoin sentiment scores DataFrame\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create the Ethereum sentiment scores DataFrame\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Describe the Bitcoin Sentiment\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Describe the Ethereum Sentiment\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Section Two: Natural Language Processing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize the text for BTC and ETH using NLTK and Python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\r\n",
    "from string import punctuation\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Instantiate the lemmatizer\r\n",
    "\r\n",
    "\r\n",
    "# Create a list of stopwords\r\n",
    "\r\n",
    "\r\n",
    "# Expand the default stopwords list if necessary\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Complete the tokenizer function\r\n",
    "def tokenizer(text):\r\n",
    "    \"\"\"Tokenizes text.\"\"\"\r\n",
    "    \r\n",
    "    # Remove the punctuation from text\r\n",
    "\r\n",
    "   \r\n",
    "    # Create a tokenized list of the words\r\n",
    "    \r\n",
    "    \r\n",
    "    # Lemmatize words into root words\r\n",
    "\r\n",
    "   \r\n",
    "    # Convert the words to lowercase\r\n",
    "    \r\n",
    "    \r\n",
    "    # Remove the stop words\r\n",
    "    \r\n",
    "    \r\n",
    "    return tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new tokens column for Bitcoin\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new tokens column for Ethereum\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using ngrams and word frequency for each coin. \r\n",
    "Use NLTK to produce the n-grams for N = 2. \r\n",
    "List the top 10 words for each coin."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " from collections import Counter\r\n",
    "from nltk import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Bitcoin N-grams where N=2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Ethereum N-grams where N=2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function token_count generates the top 10 words for a given coin\r\n",
    "def token_count(tokens, N=3):\r\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\r\n",
    "    return Counter(tokens).most_common(N)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use token_count to get the top 10 words for Bitcoin\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use token_count to get the top 10 words for Ethereum\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Word Clouds to summarize the news for each coin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from wordcloud import WordCloud\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "plt.style.use('seaborn-whitegrid')\r\n",
    "import matplotlib as mpl\r\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Bitcoin word cloud\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the Ethereum word cloud\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section Three: Named Entity Recognition\r\n",
    "## building a named entity recognition model for BTC & ETH\r\n",
    "## visualizing the tags using SpaCy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import spacy\r\n",
    "from spacy import displacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download the language model for SpaCy\r\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the spaCy model\r\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BTC NER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatenate all of the Bitcoin text together\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the NER processor on all of the text\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add a title to the document\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Render the visualization\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List all Entities\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ETH NER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatenate all of the Ethereum text together\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the NER processor on all of the text\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Render the visualization\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List all Entities\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}